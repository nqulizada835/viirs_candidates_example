{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe9592f3-0e1d-40ac-af59-7eb7d05c463d",
   "metadata": {},
   "source": [
    "Search for granules on the cloud for a box of interest, run custom candidate fire pixel extraction, map I4 + custom candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9501ee4f-413b-4d7b-b57b-f020fafd2b1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#conda activate /projects/myenvs/candidates-env\n",
    "import xarray as xr\n",
    "import earthaccess\n",
    "from earthaccess import Auth, Store, DataCollections, DataGranules\n",
    "import datetime as dt\n",
    "import time\n",
    "import os\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import folium\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import pandas as pd\n",
    "import rioxarray\n",
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e909ee04-4f90-4725-b63b-88dd8e8ab6ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_dir = '/projects/shared-buckets/qulizad/scripts/outputs/canada/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1f65a4ad-753a-4723-a7e9-46e1ac31be48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_dir(fire_name):\n",
    "    if not os.path.isdir(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "\n",
    "    if not os.path.isdir(output_dir + fire_name):\n",
    "        os.mkdir(output_dir + fire_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bf429461-299f-4e02-bdde-f288fe4e7a3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fetch_data(satellite):\n",
    "    \n",
    "    if satellite=='SNPP': products = ['VNP03IMG','VNP02IMG','VNP14IMG']\n",
    "    elif satellite=='NOAA20': products = ['VJ103IMG','VJ102IMG','VJ114IMG']\n",
    "    \n",
    "    s3_links = {}\n",
    "    files = {}\n",
    "    for product in products:\n",
    "        #query for granules - by bounding box or point\n",
    "        Query = DataGranules().short_name(product).bounding_box(EXTENT[0],EXTENT[1],EXTENT[2],EXTENT[3]).temporal(START,END)\n",
    "\n",
    "        cloud_granules = Query.get(800) #first 800 results\n",
    "\n",
    "        #save granule URLs to list\n",
    "        s3_links[product] = []\n",
    "        for granule in cloud_granules:\n",
    "            s3_links[product].extend(granule.data_links(access=\"direct\"))\n",
    "        s3_links[product] = sorted(s3_links[product]) \n",
    "        files[product] = store.open(s3_links[product], provider=\"LAADS\")\n",
    "\n",
    "    return s3_links, files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "67af5663-3278-4da0-94bc-8da564d6223c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granules found: 19\n",
      "Opening 10 granules, approx size: 1.65 GB\n",
      "using provider: LAADS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QUEUEING TASKS | : 10it [00:00, 1845.35it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 10/10 [00:00<00:00, 137.99it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 10/10 [00:00<00:00, 92182.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granules found: 19\n",
      "Opening 10 granules, approx size: 1.72 GB\n",
      "using provider: LAADS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QUEUEING TASKS | : 10it [00:00, 1924.43it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 10/10 [00:00<00:00, 500.23it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 10/10 [00:00<00:00, 141699.46it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'VNP03IMG': [<File-like object S3FileSystem, prod-lads/VNP03IMG/VNP03IMG.A2023122.0848.002.2023122170637.nc>,\n",
       "  <File-like object S3FileSystem, prod-lads/VNP03IMG/VNP03IMG.A2023122.1030.002.2023122184811.nc>,\n",
       "  <File-like object S3FileSystem, prod-lads/VNP03IMG/VNP03IMG.A2023122.1836.002.2023123012302.nc>,\n",
       "  <File-like object S3FileSystem, prod-lads/VNP03IMG/VNP03IMG.A2023122.2018.002.2023123044510.nc>,\n",
       "  <File-like object S3FileSystem, prod-lads/VNP03IMG/VNP03IMG.A2023123.0830.002.2023123165012.nc>,\n",
       "  <File-like object S3FileSystem, prod-lads/VNP03IMG/VNP03IMG.A2023123.1006.002.2023123182615.nc>,\n",
       "  <File-like object S3FileSystem, prod-lads/VNP03IMG/VNP03IMG.A2023123.1818.002.2023124031745.nc>,\n",
       "  <File-like object S3FileSystem, prod-lads/VNP03IMG/VNP03IMG.A2023123.2000.002.2023124050027.nc>,\n",
       "  <File-like object S3FileSystem, prod-lads/VNP03IMG/VNP03IMG.A2023124.0806.002.2023124163101.nc>,\n",
       "  <File-like object S3FileSystem, prod-lads/VNP03IMG/VNP03IMG.A2023124.0948.002.2023124163229.nc>],\n",
       " 'VNP02IMG': [<File-like object S3FileSystem, prod-lads/VNP02IMG/VNP02IMG.A2023122.0848.002.2023122172341.nc>,\n",
       "  <File-like object S3FileSystem, prod-lads/VNP02IMG/VNP02IMG.A2023122.1030.002.2023122190517.nc>,\n",
       "  <File-like object S3FileSystem, prod-lads/VNP02IMG/VNP02IMG.A2023122.1836.002.2023123013919.nc>,\n",
       "  <File-like object S3FileSystem, prod-lads/VNP02IMG/VNP02IMG.A2023122.2018.002.2023123050138.nc>,\n",
       "  <File-like object S3FileSystem, prod-lads/VNP02IMG/VNP02IMG.A2023123.0830.002.2023123170729.nc>,\n",
       "  <File-like object S3FileSystem, prod-lads/VNP02IMG/VNP02IMG.A2023123.1006.002.2023123184726.nc>,\n",
       "  <File-like object S3FileSystem, prod-lads/VNP02IMG/VNP02IMG.A2023123.1818.002.2023124033729.nc>,\n",
       "  <File-like object S3FileSystem, prod-lads/VNP02IMG/VNP02IMG.A2023123.2000.002.2023124051928.nc>,\n",
       "  <File-like object S3FileSystem, prod-lads/VNP02IMG/VNP02IMG.A2023124.0806.002.2023124170823.nc>,\n",
       "  <File-like object S3FileSystem, prod-lads/VNP02IMG/VNP02IMG.A2023124.0948.002.2023124180529.nc>]}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#first get the L1 geolocation and science data via direct S3 access\n",
    "#may require restarting the kernel if permission errors\n",
    "\n",
    "files = {}\n",
    "\n",
    "#geolocation 03IMG\n",
    "results = earthaccess.search_data(\n",
    "    short_name=products[0],\n",
    "    bounding_box=(EXTENT[0],EXTENT[1],EXTENT[2],EXTENT[3]),\n",
    "    temporal=(START, END),\n",
    "    count=10\n",
    ")\n",
    "files[products[0]] = earthaccess.open(results)\n",
    "\n",
    "#science data 02IMG\n",
    "results = earthaccess.search_data(\n",
    "    short_name=products[1],\n",
    "    bounding_box=(EXTENT[0],EXTENT[1],EXTENT[2],EXTENT[3]),\n",
    "    temporal=(START, END),\n",
    "    count=10\n",
    ")\n",
    "files[products[1]] = earthaccess.open(results)\n",
    "\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b7af00c1-62c3-40a6-b8ff-815af23fe2d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A2023122', '0848']\n",
      "error with file ['A2023122', '0848']\n",
      "['A2023122', '1030']\n",
      "error with file ['A2023122', '1030']\n",
      "['A2023122', '1836']\n",
      "error with file ['A2023122', '1836']\n",
      "['A2023122', '2018']\n",
      "error with file ['A2023122', '2018']\n",
      "['A2023123', '0830']\n",
      "error with file ['A2023123', '0830']\n",
      "['A2023123', '1006']\n",
      "error with file ['A2023123', '1006']\n",
      "['A2023123', '1818']\n",
      "error with file ['A2023123', '1818']\n",
      "['A2023123', '2000']\n",
      "error with file ['A2023123', '2000']\n",
      "['A2023124', '0806']\n",
      "error with file ['A2023124', '0806']\n",
      "['A2023124', '0948']\n",
      "error with file ['A2023124', '0948']\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "all_dets = pd.DataFrame()\n",
    "\n",
    "for i in range(len(files[products[0]])): #VNP03IMG or VJ103IMG\n",
    "    timestamp = files[products[0]][i].path.split('.')[-5:-3]\n",
    "    print(timestamp)\n",
    "    year = timestamp[0][1:5]\n",
    "    day = timestamp[0][5:8]\n",
    "    time = timestamp[1]\n",
    "    date = dt.datetime.strptime(year+day, '%Y%j').strftime('%b %d') \n",
    "    acq_datetime = dt.datetime.strptime(year+day+time[:2]+time[2:], '%Y%j%H%M').strftime('%Y-%m-%d %H:%M:00 +00:00') \n",
    "    daytime = int(time) > 1500 #depends on timezone\n",
    "\n",
    "    try:\n",
    "        #open 03IMG geolocation\n",
    "        geo = xr.open_dataset(files[products[0]][i], engine='h5netcdf', group='geolocation_data')\n",
    "        lon = geo['longitude'][:]\n",
    "        lat = geo['latitude'][:]\n",
    "        _, j = np.indices(geo.longitude.shape) #line and sample\n",
    "        \n",
    "        scene = (lon > EXTENT[0]) & (lon < EXTENT[2]) & (lat > EXTENT[1]) & (lat < EXTENT[3])\n",
    "\n",
    "        #crop down the datasets for memory \n",
    "        indices = np.where(scene)\n",
    "        x0 = indices[0].min()\n",
    "        x1 = indices[0].max()\n",
    "        y0 = indices[1].min()\n",
    "        y1 = indices[1].max()\n",
    "\n",
    "        lon = lon[x0:x1, y0:y1]\n",
    "        lat = lat[x0:x1, y0:y1]\n",
    "        j = j[x0:x1, y0:y1]\n",
    "        \n",
    "        #open 02IMG science data, i4 band\n",
    "        data = xr.open_dataset(files[products[1]][i], engine='h5netcdf', group='observation_data')\n",
    "        data = data.sel(number_of_lines=slice(x0,x1), number_of_pixels=slice(y0,y1))\n",
    "        \n",
    "        i4 = data['I04'] #xarray already encodes the scale factor and offset\n",
    "        scale = data.I04.encoding['scale_factor']\n",
    "        offset = data.I04.encoding['add_offset']\n",
    "        i4 = (i4[:,:] - offset) / scale #return to raw values to use lookup table to temperature\n",
    "        i4 = i4.astype(int)\n",
    "        i4_bt = data['I04_brightness_temperature_lut'][:]\n",
    "        i4_bt = i4_bt[i4]\n",
    "        \n",
    "        #get VNP14IMG\n",
    "        data = xr.open_dataset(files[products[2]][i], phony_dims='sort')\n",
    "        data = data.sel(phony_dim_1=slice(x0,x1), phony_dim_2=slice(y0,y1))\n",
    "        daynight = data.DayNightFlag #string Day or Night\n",
    "        \n",
    "        qa = data.variables['algorithm QA'][:]\n",
    "        fire = data.variables['fire mask'][:]  \n",
    "        fires = (fire>6).values\n",
    "\n",
    "    except:\n",
    "        print('error with file',timestamp)\n",
    "        #stop\n",
    "        continue\n",
    "    \n",
    "    #look at QA flags data next over entire scene\n",
    "    values, counts = np.unique(qa, return_counts=True)\n",
    "\n",
    "    table = pd.DataFrame(index = values, columns=range(22,-1,-1)) #[22,21,...0]\n",
    "    for i1 in table.index:\n",
    "        b = np.binary_repr(i1, width=23)\n",
    "        b = [int(s) for s in b]\n",
    "        table.loc[i1, :] = b\n",
    "    \n",
    "    #report back all the pixels that have an 8 or 10 ~ background or candidate fires\n",
    "    keep = table[(table.loc[:,8]==1) | (table.loc[:,10]==1)].index\n",
    "    keep = (np.isin(qa[:], keep) | (fires))  #\"fires\" because some low conf are Test 16 pixel saturation\n",
    "    \n",
    "    \n",
    "    #build pandas table for exporting, following VIIRS L2 columns\n",
    "    i_dets = pd.DataFrame()\n",
    "    i_dets['longitude'] = list(lon.values[keep])\n",
    "    i_dets['latitude'] = list(lat.values[keep])\n",
    "    i_dets['fire_mask'] = list(fire.values[keep])\n",
    "    i_dets['daynight'] = daynight[0]\n",
    "    i_dets['confidence'] = i_dets.fire_mask\n",
    "    i_dets.confidence = i_dets.confidence.replace({0:'x', 1:'x', 2:'x', 3:'x', 4:'x', 5:'x', 6:'x', 7:'l', 8:'n', 9:'h'})\n",
    "    i_dets['acq_date'] = date\n",
    "    i_dets['acq_time'] = time\n",
    "    i_dets['acq_datetime'] = acq_datetime\n",
    "    i_dets['j'] = list(j[keep]) #sample number for pixel size lookup\n",
    "   \n",
    "    #crop down to defined extent\n",
    "    i_dets = i_dets[(i_dets.longitude > EXTENT[0]) & (i_dets.longitude < EXTENT[2]) & (i_dets.latitude > EXTENT[1]) & (i_dets.latitude < EXTENT[3])]\n",
    "    \n",
    "    #FIGURE ----------------\n",
    "   \n",
    "    fig, ((ax,ax2,ax3,ax4),(ax5,ax6,ax7,ax8)) = plt.subplots(2,4, gridspec_kw={'width_ratios':[3,3,3,1], 'height_ratios':[6,1]}, constrained_layout=True, subplot_kw={'projection':ccrs.Miller()}, figsize=(12,8))\n",
    "\n",
    "    #Level 1 imagery\n",
    "    ax.set_extent([EXTENT[0],EXTENT[2],EXTENT[1],EXTENT[3]])\n",
    "    plot = ax.pcolormesh(lon, lat, i4_bt, vmin=250, vmax=360, cmap='plasma', transform=ccrs.PlateCarree())\n",
    "    cbar = plt.colorbar(plot, orientation='horizontal', shrink=0.6, pad=-2.2, extend='both', ax=ax5)\n",
    "    cbar.ax.tick_params(labelsize=12)\n",
    "    cbar.set_label('I4 brightness temperature (K)', size=12)\n",
    "\n",
    "    #Level 1 imagery plus detections\n",
    "    ax2.set_extent([EXTENT[0],EXTENT[2],EXTENT[1],EXTENT[3]])\n",
    "    plot = ax2.pcolormesh(lon, lat, i4_bt, vmin=250, vmax=360, cmap='plasma', transform=ccrs.PlateCarree())\n",
    "    cbar = plt.colorbar(plot, orientation='horizontal', shrink=0.6, pad=-2.2, extend='both', ax=ax6)\n",
    "    cbar.ax.tick_params(labelsize=12)\n",
    "    cbar.set_label('I4 brightness temperature (K)', size=12)\n",
    "\n",
    "    ax2.scatter(i_dets.longitude, i_dets.latitude, c=cmp2(i_dets['fire_mask'].astype(int)), s=0.5, transform=ccrs.Geodetic())\n",
    "    ax2.text(0.2, 0.9, 'Known fire pixels', c='black', transform = ax2.transAxes, fontsize=12)\n",
    "    ax2.text(0.2, 0.85, 'Candidate fire pixels', c='white', transform = ax2.transAxes, fontsize=12)\n",
    "    ax2.set_title(f'{SATELLITE} {date} {time}h UTC')\n",
    "\n",
    "    #Level 2 fire mask\n",
    "    ax3.set_extent([EXTENT[0],EXTENT[2],EXTENT[1],EXTENT[3]])\n",
    "    plot = ax3.pcolormesh(lon, lat, fire, vmin=0, vmax=10, cmap=cmp1, transform=ccrs.PlateCarree())\n",
    "\n",
    "    #Level 2 fire mask legend\n",
    "    cbar = plt.colorbar(plot, orientation='vertical', shrink=0.8, pad=-1, ax=ax4)\n",
    "\n",
    "    labels = ['0 not-processed', '1 bowtie', '2 glint', '3 water','4 clouds',\n",
    "          '5 clear land','6 unclassified fire pixel','7 low confidence fire pixel',\n",
    "          '8 nominal confidence fire pixel','9 high confidence fire pixel']\n",
    "    cbar.ax.set_yticks(np.arange(len(labels))+0.5)\n",
    "    cbar.ax.set_yticklabels(labels) \n",
    "    cbar.ax.tick_params(labelsize=12)\n",
    "    #cbar.set_label('Fire mask', size=13)\n",
    "    #ax3.set_title('Fire mask')\n",
    "\n",
    "    ax4.axis('off')\n",
    "    ax5.axis('off')\n",
    "    ax6.axis('off')\n",
    "    ax7.axis('off')\n",
    "    ax8.axis('off')\n",
    "    plt.savefig(f'/projects/shared-buckets/coffield/figures/creek_{timestamp[0]}-{timestamp[1]}_{SATELLITE}.png', dpi=150, bbox_inches='tight')\n",
    "\n",
    "    all_dets = pd.concat([all_dets, i_dets])\n",
    "    \n",
    "#save csv with filename as the timestamp range\n",
    "#all_dets.to_csv(f'/projects/shared-buckets/coffield/??PATH??{timestamp[0]}_{SATELLITE}.csv', index=False)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "da0bcf1f-ced1-4ef0-b4bd-8e882b4b42ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 hits\n",
      "cloud hosted True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QUEUEING TASKS | : 19it [00:00, 4203.37it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 19/19 [00:00<00:00, 22.11it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 19/19 [00:00<00:00, 223853.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VNP14IMG\n",
      "{'VNP02IMG': [<File-like object S3FileSystem, prod-lads/VNP02IMG/VNP02IMG.A2023122.0848.002.2023122172341.nc>,\n",
      "              <File-like object S3FileSystem, prod-lads/VNP02IMG/VNP02IMG.A2023122.1030.002.2023122190517.nc>,\n",
      "              <File-like object S3FileSystem, prod-lads/VNP02IMG/VNP02IMG.A2023122.1836.002.2023123013919.nc>,\n",
      "              <File-like object S3FileSystem, prod-lads/VNP02IMG/VNP02IMG.A2023122.2018.002.2023123050138.nc>,\n",
      "              <File-like object S3FileSystem, prod-lads/VNP02IMG/VNP02IMG.A2023123.0830.002.2023123170729.nc>,\n",
      "              <File-like object S3FileSystem, prod-lads/VNP02IMG/VNP02IMG.A2023123.1006.002.2023123184726.nc>,\n",
      "              <File-like object S3FileSystem, prod-lads/VNP02IMG/VNP02IMG.A2023123.1818.002.2023124033729.nc>,\n",
      "              <File-like object S3FileSystem, prod-lads/VNP02IMG/VNP02IMG.A2023123.2000.002.2023124051928.nc>,\n",
      "              <File-like object S3FileSystem, prod-lads/VNP02IMG/VNP02IMG.A2023124.0806.002.2023124170823.nc>,\n",
      "              <File-like object S3FileSystem, prod-lads/VNP02IMG/VNP02IMG.A2023124.0948.002.2023124180529.nc>],\n",
      " 'VNP03IMG': [<File-like object S3FileSystem, prod-lads/VNP03IMG/VNP03IMG.A2023122.0848.002.2023122170637.nc>,\n",
      "              <File-like object S3FileSystem, prod-lads/VNP03IMG/VNP03IMG.A2023122.1030.002.2023122184811.nc>,\n",
      "              <File-like object S3FileSystem, prod-lads/VNP03IMG/VNP03IMG.A2023122.1836.002.2023123012302.nc>,\n",
      "              <File-like object S3FileSystem, prod-lads/VNP03IMG/VNP03IMG.A2023122.2018.002.2023123044510.nc>,\n",
      "              <File-like object S3FileSystem, prod-lads/VNP03IMG/VNP03IMG.A2023123.0830.002.2023123165012.nc>,\n",
      "              <File-like object S3FileSystem, prod-lads/VNP03IMG/VNP03IMG.A2023123.1006.002.2023123182615.nc>,\n",
      "              <File-like object S3FileSystem, prod-lads/VNP03IMG/VNP03IMG.A2023123.1818.002.2023124031745.nc>,\n",
      "              <File-like object S3FileSystem, prod-lads/VNP03IMG/VNP03IMG.A2023123.2000.002.2023124050027.nc>,\n",
      "              <File-like object S3FileSystem, prod-lads/VNP03IMG/VNP03IMG.A2023124.0806.002.2023124163101.nc>,\n",
      "              <File-like object S3FileSystem, prod-lads/VNP03IMG/VNP03IMG.A2023124.0948.002.2023124163229.nc>],\n",
      " 'VNP14IMG': [<File-like object HTTPFileSystem, https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/VNP14IMG.002/VNP14IMG.A2023122.0848.002.2024079061411/VNP14IMG.A2023122.0848.002.2024079061411.nc>,\n",
      "              <File-like object HTTPFileSystem, https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/VNP14IMG.002/VNP14IMG.A2023122.1030.002.2024079061412/VNP14IMG.A2023122.1030.002.2024079061412.nc>,\n",
      "              <File-like object HTTPFileSystem, https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/VNP14IMG.002/VNP14IMG.A2023122.1836.002.2024079061425/VNP14IMG.A2023122.1836.002.2024079061425.nc>,\n",
      "              <File-like object HTTPFileSystem, https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/VNP14IMG.002/VNP14IMG.A2023122.2018.002.2024079061421/VNP14IMG.A2023122.2018.002.2024079061421.nc>,\n",
      "              <File-like object HTTPFileSystem, https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/VNP14IMG.002/VNP14IMG.A2023123.0830.002.2024079062147/VNP14IMG.A2023123.0830.002.2024079062147.nc>,\n",
      "              <File-like object HTTPFileSystem, https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/VNP14IMG.002/VNP14IMG.A2023123.1006.002.2024079062147/VNP14IMG.A2023123.1006.002.2024079062147.nc>,\n",
      "              <File-like object HTTPFileSystem, https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/VNP14IMG.002/VNP14IMG.A2023123.1818.002.2024079062151/VNP14IMG.A2023123.1818.002.2024079062151.nc>,\n",
      "              <File-like object HTTPFileSystem, https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/VNP14IMG.002/VNP14IMG.A2023123.2000.002.2024079062149/VNP14IMG.A2023123.2000.002.2024079062149.nc>,\n",
      "              <File-like object HTTPFileSystem, https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/VNP14IMG.002/VNP14IMG.A2023124.0806.002.2024079063117/VNP14IMG.A2023124.0806.002.2024079063117.nc>,\n",
      "              <File-like object HTTPFileSystem, https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/VNP14IMG.002/VNP14IMG.A2023124.0948.002.2024079063119/VNP14IMG.A2023124.0948.002.2024079063119.nc>,\n",
      "              <File-like object HTTPFileSystem, https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/VNP14IMG.002/VNP14IMG.A2023124.1130.002.2024079063120/VNP14IMG.A2023124.1130.002.2024079063120.nc>,\n",
      "              <File-like object HTTPFileSystem, https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/VNP14IMG.002/VNP14IMG.A2023124.1800.002.2024079063122/VNP14IMG.A2023124.1800.002.2024079063122.nc>,\n",
      "              <File-like object HTTPFileSystem, https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/VNP14IMG.002/VNP14IMG.A2023124.1942.002.2024079063119/VNP14IMG.A2023124.1942.002.2024079063119.nc>,\n",
      "              <File-like object HTTPFileSystem, https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/VNP14IMG.002/VNP14IMG.A2023124.2124.002.2024079063123/VNP14IMG.A2023124.2124.002.2024079063123.nc>,\n",
      "              <File-like object HTTPFileSystem, https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/VNP14IMG.002/VNP14IMG.A2023125.0748.002.2024079064456/VNP14IMG.A2023125.0748.002.2024079064456.nc>,\n",
      "              <File-like object HTTPFileSystem, https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/VNP14IMG.002/VNP14IMG.A2023125.0930.002.2024079064455/VNP14IMG.A2023125.0930.002.2024079064455.nc>,\n",
      "              <File-like object HTTPFileSystem, https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/VNP14IMG.002/VNP14IMG.A2023125.1112.002.2024079064453/VNP14IMG.A2023125.1112.002.2024079064453.nc>,\n",
      "              <File-like object HTTPFileSystem, https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/VNP14IMG.002/VNP14IMG.A2023125.1924.002.2024079064454/VNP14IMG.A2023125.1924.002.2024079064454.nc>,\n",
      "              <File-like object HTTPFileSystem, https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/VNP14IMG.002/VNP14IMG.A2023125.2100.002.2024079064456/VNP14IMG.A2023125.2100.002.2024079064456.nc>]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "product = products[2]\n",
    "\n",
    "Query = DataGranules().short_name(product).bounding_box(EXTENT[0],EXTENT[1],EXTENT[2],EXTENT[3]).temporal(START,END)\n",
    "\n",
    "print(Query.hits(), 'hits')\n",
    "cloud_granules = Query.get(800) #first 800 results\n",
    "print('cloud hosted', cloud_granules[0].cloud_hosted)\n",
    "\n",
    "s3_links = {}\n",
    "s3_links[product] = []\n",
    "for granule in cloud_granules:\n",
    "    s3_links[product].extend(granule.data_links(access=\"in-region\"))\n",
    "s3_links[product] = sorted(s3_links[product]) \n",
    "files[product] = store.open(s3_links[product], provider=\"LAADS\")\n",
    "\n",
    "print(product)\n",
    "pprint(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "786ee0fa-a8d2-4dbd-b0ae-4b191035bac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "mask_colors = [mpl.colormaps['tab10'](c) for c in [4,6,5,0,9,2,7,8,1,3]] #fire mask colors\n",
    "dets_colors = ['white']*7 + ['black']*3                                  #black and white version\n",
    "\n",
    "cmp1 = ListedColormap(mask_colors)\n",
    "cmp2 = ListedColormap(dets_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c94e1bf-14f5-455a-9620-755829c782f7",
   "metadata": {},
   "source": [
    "Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "444807f1-9b66-44da-ba43-2d22a6e2a35e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#start = time.time()\n",
    "#start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0d58fa7a-0892-45a0-a90a-a119524081e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#read in pyroCB catalog\n",
    "file = f'/projects/shared-buckets/qulizad/NRL_pyroCb_inventory_2023_v1.csv'\n",
    "df = pd.read_csv(file, header=0, usecols=[\"datetime\", \"fire_name\", \"region\", \"lat\", \"lon\"])\n",
    "rslt_df = df.loc[(df['region'] == 'Canada')]  #.reset_index(drop=True) #subsetting to Canada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "aa7d9423-3d93-4cc7-8ba6-613b10bfd533",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#rslt_df.loc[25] ## only prints up to not including 10th record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "befb693f-8454-4571-8d58-ff40de92b9ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#initiate cloud session - need to reauthenticate every hour :(\n",
    "\n",
    "auth = Auth() \n",
    "#auth.login(strategy=\"interactive\", persist=True) #RUN THIS THE FIRST TIME\n",
    "auth.login(strategy=\"netrc\") #read credentials from previously saved ~/.netrc file\n",
    "\n",
    "store = Store(auth)\n",
    "fs = store.get_s3fs_session('LAADS') #daac or provider name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4c9b1ac2-cd70-4ad0-8af6-a7c7abdfdfc8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 23BN-VERMETTE 2023-05-04 23:10:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QUEUEING TASKS | : 19it [00:00, 1812.41it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 19/19 [00:01<00:00, 17.01it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 19/19 [00:00<00:00, 235078.99it/s]\n",
      "QUEUEING TASKS | : 19it [00:00, 2562.11it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 19/19 [00:00<00:00, 420.63it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 19/19 [00:00<00:00, 154741.31it/s]\n",
      "QUEUEING TASKS | : 19it [00:00, 3251.66it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 19/19 [00:00<00:00, 88.70it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 19/19 [00:00<00:00, 155042.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A2023122', '0848']\n",
      "error with file or does not exist ['A2023122', '0848']\n",
      "['A2023122', '1030']\n",
      "error with file or does not exist ['A2023122', '1030']\n",
      "['A2023122', '1836']\n",
      "error with file or does not exist ['A2023122', '1836']\n",
      "['A2023122', '2018']\n",
      "error with file or does not exist ['A2023122', '2018']\n",
      "['A2023123', '0830']\n",
      "error with file or does not exist ['A2023123', '0830']\n",
      "['A2023123', '1006']\n",
      "error with file or does not exist ['A2023123', '1006']\n",
      "['A2023123', '1818']\n",
      "error with file or does not exist ['A2023123', '1818']\n",
      "['A2023123', '2000']\n",
      "error with file or does not exist ['A2023123', '2000']\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 30] Read-only file system: '/projects/shared-buckets/qulizad/scripts/outputs/canada//A2023123_SNPP.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 43\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m s\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSNPP\u001b[39m\u001b[38;5;124m'\u001b[39m: products \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVNP03IMG\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVNP02IMG\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVNP14IMG\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m s\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNOAA20\u001b[39m\u001b[38;5;124m'\u001b[39m: products \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVJ103IMG\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVJ102IMG\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVJ114IMG\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 43\u001b[0m \u001b[43mrun_fire_algorithm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#using level 1 data\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m#run_custom_fire_algorithm(s3_links, files) #using level 1 data\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m#run_viirs_l2_fire_algoithm(s3_links, files) #using level 2 data\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[40], line 120\u001b[0m, in \u001b[0;36mrun_fire_algorithm\u001b[0;34m()\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m#save csv with filename as the timestamp range\u001b[39;00m\n\u001b[1;32m    119\u001b[0m filecsv \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimestamp[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 120\u001b[0m \u001b[43mall_dets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilecsv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/myenvs/candidates-env/lib/python3.9/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenvs/candidates-env/lib/python3.9/site-packages/pandas/core/generic.py:3720\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3709\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[1;32m   3711\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3712\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m   3713\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3717\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   3718\u001b[0m )\n\u001b[0;32m-> 3720\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3723\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3724\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3725\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3726\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3727\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3728\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3731\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3732\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3733\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3734\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3735\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3737\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenvs/candidates-env/lib/python3.9/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenvs/candidates-env/lib/python3.9/site-packages/pandas/io/formats/format.py:1189\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1168\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1170\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[1;32m   1171\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[1;32m   1172\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1187\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[1;32m   1188\u001b[0m )\n\u001b[0;32m-> 1189\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1192\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m~/myenvs/candidates-env/lib/python3.9/site-packages/pandas/io/formats/csvs.py:241\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[0;32m--> 241\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    249\u001b[0m \n\u001b[1;32m    250\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[1;32m    252\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m    253\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    258\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[1;32m    259\u001b[0m     )\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[0;32m~/myenvs/candidates-env/lib/python3.9/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 30] Read-only file system: '/projects/shared-buckets/qulizad/scripts/outputs/canada//A2023123_SNPP.csv'"
     ]
    }
   ],
   "source": [
    "#loop through all pyroCBs, run methods to make output directories, fetch data, and generate candidate fires\n",
    "\n",
    "#%time\n",
    "# %time is not the same as %%time because the former only see's how long the current \n",
    "#line takes to execute, whereas the latter checks the how the current line and \n",
    "#following lines take to execute\n",
    "#[:] is the array slice syntax for every element in the array\n",
    "\n",
    "#start time \n",
    "\n",
    "for i in rslt_df.index[1:2]:\n",
    "    #if i%5==0: #reauthenticate\n",
    "    \n",
    "    #current & elapsed = ...\n",
    "    #if elapsed > 0.98: #reauthenticate, reset \"start\" time\n",
    "        \n",
    "    fire_name = rslt_df.loc[i, 'fire_name']\n",
    "    lat = rslt_df.loc[i, 'lat']\n",
    "    lon = rslt_df.loc[i, 'lon']\n",
    "    dat = rslt_df.loc[i, 'datetime']\n",
    "    date_object = dt.datetime.strptime(dat, \"%m/%d/%y %H:%M\")    \n",
    "    print(i, fire_name, date_object)\n",
    "    \n",
    "    start_date = date_object + dt.timedelta(-2)\n",
    "    end_date = date_object + dt.timedelta(+2)\n",
    "    \n",
    "    start_date = start_date.strftime(\"%Y-%m-%d\")\n",
    "    end_date = end_date.strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    make_dir(fire_name)\n",
    "\n",
    "    EXTENT = [lon - 0.5, lat - 0.5, lon + 0.5, lat + 0.5]\n",
    "    START = start_date\n",
    "    END = end_date\n",
    "    \n",
    "    satellites = ['SNPP','NOAA20']\n",
    "    for s in satellites:\n",
    "        s3_links, files = fetch_data(s)\n",
    "        \n",
    "        if s=='SNPP': products = ['VNP03IMG','VNP02IMG','VNP14IMG']\n",
    "        elif s=='NOAA20': products = ['VJ103IMG','VJ102IMG','VJ114IMG']\n",
    "        \n",
    "        run_fire_algorithm() #using level 1 data\n",
    "\n",
    "        #run_custom_fire_algorithm(s3_links, files) #using level 1 data\n",
    "        #run_viirs_l2_fire_algoithm(s3_links, files) #using level 2 data\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569cd1a9-adb0-47f5-85ce-aade2b51c7f6",
   "metadata": {
    "tags": []
   },
   "source": [
    "def run_fire_algorithm():\n",
    "    all_dets = pd.DataFrame()\n",
    "    \n",
    "    products = list(s3_links.keys())\n",
    "\n",
    "    for i in range(len(products[0])): #VNP02IMG or VJ102IMG\n",
    "        timestamp = s3_links[products[0]][i].split('.')[1:3]\n",
    "        print(timestamp)\n",
    "        year = timestamp[0][1:5]\n",
    "        day = timestamp[0][5:8]\n",
    "        time = timestamp[1]\n",
    "        date = dt.datetime.strptime(year+day, '%Y%j').strftime('%b %d') \n",
    "        acq_datetime = dt.datetime.strptime(year+day+time[:2]+time[2:], '%Y%j%H%M').strftime('%Y-%m-%d %H:%M:00 +00:00') \n",
    "        daytime = int(time) > 1500 #depends on timezone\n",
    "        \n",
    "        try:\n",
    "            #open VNP03IMG geolocation\n",
    "            geo = xr.open_dataset(files[products[1]][i], engine='h5netcdf', group='geolocation_data')\n",
    "            lon = geo['longitude'][:]\n",
    "            lat = geo['latitude'][:]\n",
    "\n",
    "            scene = (lon > EXTENT[0]) & (lon < EXTENT[2]) & (lat > EXTENT[1]) & (lat < EXTENT[3])\n",
    "\n",
    "            #crop down the datasets for memory \n",
    "            indices = np.where(scene)\n",
    "            x0 = indices[0].min()\n",
    "            x1 = indices[0].max()\n",
    "            y0 = indices[1].min()\n",
    "            y1 = indices[1].max()\n",
    "\n",
    "            lon = lon[x0:x1, y0:y1]\n",
    "            lat = lat[x0:x1, y0:y1]\n",
    "\n",
    "            #get VNP02IMG science data, i1-i5 bands\n",
    "            data = xr.open_dataset(files[products[0]][i], engine='h5netcdf', group='observation_data')\n",
    "            data = data.sel(number_of_lines=slice(x0,x1), number_of_pixels=slice(y0,y1))\n",
    "\n",
    "            i4 = data['I04'] #xarray already encodes the scale factor and offset\n",
    "            scale = data.I04.encoding['scale_factor']\n",
    "            offset = data.I04.encoding['add_offset']\n",
    "            i4 = (i4[:,:] - offset) / scale #return to raw values to use lookup table to temperature\n",
    "            i4 = i4.astype(int)\n",
    "            i4_bt = data['I04_brightness_temperature_lut'][:]\n",
    "            i4_bt = i4_bt[i4]\n",
    "\n",
    "            i5 = data['I05']\n",
    "            scale = data.I05.encoding['scale_factor']\n",
    "            offset = data.I05.encoding['add_offset']\n",
    "            i5 = (i5[:,:] - offset) / scale\n",
    "            i5 = i5.astype(int)\n",
    "            i5_bt = data['I05_brightness_temperature_lut'][:]\n",
    "            i5_bt = i5_bt[i5]\n",
    "\n",
    "        except:\n",
    "            print('error with file or does not exist',timestamp)\n",
    "            continue\n",
    "\n",
    "\n",
    "        if daytime:\n",
    "            clouds = (i5_bt < 265) | ((data.I01+data.I02 > 0.9) & (i5_bt < 295)) | ((data.I01+data.I02 > 0.7) & (i5_bt < 285)) \n",
    "            water = (data.I01 > data.I02) & (data.I02 > data.I03)\n",
    "            saturated = (i4_bt==367) & (data.I04_quality_flags==9) & (data.I05_quality_flags==0) & (i5_bt > 290) & (data.I01+data.I02 < 0.7)\n",
    "            folded = (i4_bt-i5_bt < 0) & (i5_bt > 325) & (data.I05_quality_flags==0)\n",
    "            bg_fires = ((i4_bt > 335) & (i4_bt-i5_bt > 30)) | (folded)\n",
    "            bright = (data.I03 > 0.3) & (data.I03 > data.I02) & (data.I02 > 0.25) & (i4_bt <335)\n",
    "            #glint = come back to this\n",
    "            candidates = (~bright) & (i4_bt > 325) & (i4_bt-i5_bt > 25) #double check this isn't contextual\n",
    "\n",
    "            fires =  (saturated | folded | bg_fires | candidates) #~clouds & ~water &\n",
    "\n",
    "        else: #nighttime\n",
    "            clouds = (i5_bt < 265) & (i4_bt < 295)\n",
    "            unequivocal = (i4_bt > 320) & (data.I04_quality_flags==0)\n",
    "            saturated = (i4_bt==367) & (data.I04_quality_flags==9) & (data.I05_quality_flags==0)\n",
    "            folded = ((i4_bt-i5_bt < 0) & (i5_bt > 310) & (data.I05_quality_flags==0)) | ((i4_bt > 208) & (i5_bt > 335))\n",
    "            bg_fires = ((i4_bt > 300) & (i4_bt-i5_bt > 10)) | (folded)\n",
    "            #bright = water #all false\n",
    "            candidates = (i4_bt > 295) & (i4_bt-i5_bt > 10) \n",
    "\n",
    "            fires = (unequivocal | saturated | folded | bg_fires | candidates) #~clouds & \n",
    "\n",
    "\n",
    "        #build pandas table for exporting, following VIIRS L2 columns\n",
    "        i_dets = pd.DataFrame() #copy of master table just for this swath\n",
    "        i_dets['longitude'] = list(np.array(lon)[fires])\n",
    "        i_dets['latitude'] = list(np.array(lat)[fires])\n",
    "        i_dets['acq_date'] = dt.datetime.strptime(year+day, '%Y%j').strftime('%Y/%m/%d') \n",
    "        i_dets['acq_time'] = time\n",
    "        i_dets['acq_datetime'] = acq_datetime\n",
    "\n",
    "        #crop down to defined extent\n",
    "        i_dets = i_dets[(i_dets.longitude > EXTENT[0]) & (i_dets.longitude < EXTENT[2]) & (i_dets.latitude > EXTENT[1]) & (i_dets.latitude < EXTENT[3])]\n",
    "\n",
    "        #FIGURE ----------------\n",
    "        fig = plt.figure(figsize=(11,8))\n",
    "\n",
    "        ax = fig.add_subplot(121, projection=ccrs.Miller())\n",
    "        ax.set_extent([EXTENT[0],EXTENT[2],EXTENT[1],EXTENT[3]])\n",
    "        plot = ax.pcolormesh(lon, lat, i4_bt, vmin=250, vmax=360, cmap='plasma', transform=ccrs.PlateCarree())\n",
    "        cbar = plt.colorbar(plot, orientation='horizontal', shrink=0.6, pad=0.01, extend='both', ax=ax)\n",
    "        cbar.ax.tick_params(labelsize=13)\n",
    "        cbar.set_label('I4 brightness temperature (K)', size=13)\n",
    "        ax.set_title(f'{s} {date} {time}h UTC') \n",
    "             \n",
    "        ax2 = fig.add_subplot(122, projection=ccrs.Miller())\n",
    "        ax2.set_extent([EXTENT[0],EXTENT[2],EXTENT[1],EXTENT[3]])\n",
    "        plot = ax2.pcolormesh(lon, lat, i4_bt, vmin=250, vmax=360, cmap='plasma', transform=ccrs.PlateCarree())\n",
    "        cbar = plt.colorbar(plot, orientation='horizontal', shrink=0.6, pad=0.01, extend='both', ax=ax2)\n",
    "        cbar.ax.tick_params(labelsize=13)\n",
    "        cbar.set_label('I4 brightness temperature (K)', size=13)\n",
    "        ax2.scatter(i_dets.longitude, i_dets.latitude, c='1', s=1, transform=ccrs.Geodetic())\n",
    "        ax2.text(0.35, 0.9, 'Potential fire pixels', c='white', transform = ax2.transAxes)\n",
    "        figimgs = (f'{output_dir}/{fire_name}/{timestamp[0]}-{timestamp[1]}_{s}.png')\n",
    "        plt.savefig(figimgs, dpi=100)\n",
    "        plt.close()\n",
    "        all_dets = pd.concat([all_dets, i_dets])\n",
    "    \n",
    "    #save csv with filename as the timestamp range\n",
    "    filecsv = (f'{output_dir}/{timestamp[0]}_{s}.csv')\n",
    "    all_dets.to_csv(filecsv, index=False)\n",
    "\n",
    "    print('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python candidatesenv",
   "language": "python",
   "name": "candidates-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
