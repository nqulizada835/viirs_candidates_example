{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fb1535c-397c-43c1-b144-a70eb241f542",
   "metadata": {},
   "source": [
    "Searching for VIIRS L2 fire data (swaths and text files) in the cloud and checking which versions are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ec1ddf-cb08-4f47-8151-eaa8d668b21b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import earthaccess\n",
    "from earthaccess import Auth, Store, DataCollections, DataGranules\n",
    "import datetime as dt\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "#optional for plotting\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2e6ba6-c4f8-4a23-9aa8-b6d3bf4518a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EXTENT = [-119.55,36.95,-118.9,37.7] #creek fire\n",
    "\n",
    "START = '2020-09-06'\n",
    "END = '2020-09-08'\n",
    "#dates converted to UTC time; end date is exclusive\n",
    "\n",
    "SATELLITE = 'SNPP' #'SNPP' or 'NOAA20'\n",
    "\n",
    "if SATELLITE=='SNPP': products = ['VNP03IMG','VNP02IMG','VNP14IMG']\n",
    "elif SATELLITE=='NOAA20': products = ['VJ103IMG','VJ102IMG','VJ114IMG'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7e648a-02e7-4acd-b13c-31b8cb5ee7c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#first get the L1 geolocation and science data via direct S3 access\n",
    "#may require restarting the kernel if permission errors\n",
    "\n",
    "files = {}\n",
    "\n",
    "#geolocation 03IMG\n",
    "results = earthaccess.search_data(\n",
    "    short_name=products[0],\n",
    "    bounding_box=(EXTENT[0],EXTENT[1],EXTENT[2],EXTENT[3]),\n",
    "    temporal=(START, END),\n",
    "    count=10\n",
    ")\n",
    "files[products[0]] = earthaccess.open(results)\n",
    "\n",
    "#science data 02IMG\n",
    "results = earthaccess.search_data(\n",
    "    short_name=products[1],\n",
    "    bounding_box=(EXTENT[0],EXTENT[1],EXTENT[2],EXTENT[3]),\n",
    "    temporal=(START, END),\n",
    "    count=10\n",
    ")\n",
    "files[products[1]] = earthaccess.open(results)\n",
    "\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728bcac1-6f26-4fab-8e00-1f2f36377d19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#next get the Level2 files - need to login to LAADS\n",
    "#was getting permission errors trying to do both with the same method - likely related to region storage\n",
    "\n",
    "auth = Auth() #need to reauthenticate every hour or so :(\n",
    "#auth.login(strategy=\"interactive\", persist=True) #RUN THIS THE FIRST TIME\n",
    "auth.login(strategy=\"netrc\") #read credentials from previously saved ~/.netrc file\n",
    "\n",
    "store = Store(auth)\n",
    "fs = store.get_s3fs_session('LAADS') #daac or provider name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d299d24e-5e1c-4e4b-8c3f-10c32cac5e23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "product = products[2]\n",
    "\n",
    "Query = DataGranules().short_name(product).bounding_box(EXTENT[0],EXTENT[1],EXTENT[2],EXTENT[3]).temporal(START,END)\n",
    "\n",
    "print(Query.hits(), 'hits')\n",
    "cloud_granules = Query.get(800) #first 800 results\n",
    "print('cloud hosted', cloud_granules[0].cloud_hosted)\n",
    "\n",
    "s3_links = {}\n",
    "s3_links[product] = []\n",
    "for granule in cloud_granules:\n",
    "    s3_links[product].extend(granule.data_links(access=\"in-region\"))\n",
    "s3_links[product] = sorted(s3_links[product]) \n",
    "files[product] = store.open(s3_links[product], provider=\"LAADS\")\n",
    "\n",
    "print(product)\n",
    "pprint(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6540247e-d13c-485c-ab39-1dec944b2e48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#test open one 03IMG geolocation (optional)\n",
    "xr.open_dataset(files[products[0]][0], engine='h5netcdf', group='geolocation_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e698fe-1bb6-4375-8a11-40443c1512b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#test open one 14IMG level 2 (optional)\n",
    "xr.open_dataset(files[products[2]][0], phony_dims='sort')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f42359-7d1e-4c3c-bf71-8a9ad5de309a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "files[products[0]][0].path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8782c1-a3b5-4a02-83f7-d3510dc2f0ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "files[products[2]][1].path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b746a8f-c509-4c92-a24d-67479d5b1462",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "mask_colors = [mpl.colormaps['tab10'](c) for c in [4,6,5,0,9,2,7,8,1,3]] #fire mask colors\n",
    "dets_colors = ['white']*7 + ['black']*3                                  #black and white version\n",
    "\n",
    "cmp1 = ListedColormap(mask_colors)\n",
    "cmp2 = ListedColormap(dets_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22099dfd-7f57-4ebf-9ba2-ad7f94a55ec5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_dets = pd.DataFrame()\n",
    "\n",
    "for i in range(len(files[products[0]])): #VNP03IMG or VJ103IMG\n",
    "    timestamp = files[products[0]][i].path.split('.')[-5:-3]\n",
    "    print(timestamp)\n",
    "    year = timestamp[0][1:5]\n",
    "    day = timestamp[0][5:8]\n",
    "    time = timestamp[1]\n",
    "    date = dt.datetime.strptime(year+day, '%Y%j').strftime('%b %d') \n",
    "    acq_datetime = dt.datetime.strptime(year+day+time[:2]+time[2:], '%Y%j%H%M').strftime('%Y-%m-%d %H:%M:00 +00:00') \n",
    "    daytime = int(time) > 1500 #depends on timezone\n",
    "\n",
    "    try:\n",
    "        #open 03IMG geolocation\n",
    "        geo = xr.open_dataset(files[products[0]][i], engine='h5netcdf', group='geolocation_data')\n",
    "        lon = geo['longitude'][:]\n",
    "        lat = geo['latitude'][:]\n",
    "        _, j = np.indices(geo.longitude.shape) #line and sample\n",
    "        \n",
    "        scene = (lon > EXTENT[0]) & (lon < EXTENT[2]) & (lat > EXTENT[1]) & (lat < EXTENT[3])\n",
    "\n",
    "        #crop down the datasets for memory \n",
    "        indices = np.where(scene)\n",
    "        x0 = indices[0].min()\n",
    "        x1 = indices[0].max()\n",
    "        y0 = indices[1].min()\n",
    "        y1 = indices[1].max()\n",
    "\n",
    "        lon = lon[x0:x1, y0:y1]\n",
    "        lat = lat[x0:x1, y0:y1]\n",
    "        j = j[x0:x1, y0:y1]\n",
    "        \n",
    "        #open 02IMG science data, i4 band\n",
    "        data = xr.open_dataset(files[products[1]][i], engine='h5netcdf', group='observation_data')\n",
    "        data = data.sel(number_of_lines=slice(x0,x1), number_of_pixels=slice(y0,y1))\n",
    "        \n",
    "        i4 = data['I04'] #xarray already encodes the scale factor and offset\n",
    "        scale = data.I04.encoding['scale_factor']\n",
    "        offset = data.I04.encoding['add_offset']\n",
    "        i4 = (i4[:,:] - offset) / scale #return to raw values to use lookup table to temperature\n",
    "        i4 = i4.astype(int)\n",
    "        i4_bt = data['I04_brightness_temperature_lut'][:]\n",
    "        i4_bt = i4_bt[i4]\n",
    "        \n",
    "        #get VNP14IMG\n",
    "        data = xr.open_dataset(files[products[2]][i], phony_dims='sort')\n",
    "        data = data.sel(phony_dim_1=slice(x0,x1), phony_dim_2=slice(y0,y1))\n",
    "        daynight = data.DayNightFlag #string Day or Night\n",
    "        \n",
    "        qa = data.variables['algorithm QA'][:]\n",
    "        fire = data.variables['fire mask'][:]  \n",
    "        fires = (fire>6).values\n",
    "\n",
    "    except:\n",
    "        print('error with file',timestamp)\n",
    "        stop\n",
    "        continue\n",
    "    \n",
    "    #look at QA flags data next over entire scene\n",
    "    values, counts = np.unique(qa, return_counts=True)\n",
    "\n",
    "    table = pd.DataFrame(index = values, columns=range(22,-1,-1)) #[22,21,...0]\n",
    "    for i1 in table.index:\n",
    "        b = np.binary_repr(i1, width=23)\n",
    "        b = [int(s) for s in b]\n",
    "        table.loc[i1, :] = b\n",
    "    \n",
    "    #report back all the pixels that have an 8 or 10 ~ background or candidate fires\n",
    "    keep = table[(table.loc[:,8]==1) | (table.loc[:,10]==1)].index\n",
    "    keep = (np.isin(qa[:], keep) | (fires))  #\"fires\" because some low conf are Test 16 pixel saturation\n",
    "    \n",
    "    \n",
    "    #build pandas table for exporting, following VIIRS L2 columns\n",
    "    i_dets = pd.DataFrame()\n",
    "    i_dets['longitude'] = list(lon.values[keep])\n",
    "    i_dets['latitude'] = list(lat.values[keep])\n",
    "    i_dets['fire_mask'] = list(fire.values[keep])\n",
    "    i_dets['daynight'] = daynight[0]\n",
    "    i_dets['confidence'] = i_dets.fire_mask\n",
    "    i_dets.confidence = i_dets.confidence.replace({0:'x', 1:'x', 2:'x', 3:'x', 4:'x', 5:'x', 6:'x', 7:'l', 8:'n', 9:'h'})\n",
    "    i_dets['acq_date'] = date\n",
    "    i_dets['acq_time'] = time\n",
    "    i_dets['acq_datetime'] = acq_datetime\n",
    "    i_dets['j'] = list(j[keep]) #sample number for pixel size lookup\n",
    "   \n",
    "    #crop down to defined extent\n",
    "    i_dets = i_dets[(i_dets.longitude > EXTENT[0]) & (i_dets.longitude < EXTENT[2]) & (i_dets.latitude > EXTENT[1]) & (i_dets.latitude < EXTENT[3])]\n",
    "    \n",
    "    #FIGURE ----------------\n",
    "   \n",
    "    fig, ((ax,ax2,ax3,ax4),(ax5,ax6,ax7,ax8)) = plt.subplots(2,4, gridspec_kw={'width_ratios':[3,3,3,1], 'height_ratios':[6,1]}, constrained_layout=True, subplot_kw={'projection':ccrs.Miller()}, figsize=(12,8))\n",
    "\n",
    "    #Level 1 imagery\n",
    "    ax.set_extent([EXTENT[0],EXTENT[2],EXTENT[1],EXTENT[3]])\n",
    "    plot = ax.pcolormesh(lon, lat, i4_bt, vmin=250, vmax=360, cmap='plasma', transform=ccrs.PlateCarree())\n",
    "    cbar = plt.colorbar(plot, orientation='horizontal', shrink=0.6, pad=-2.2, extend='both', ax=ax5)\n",
    "    cbar.ax.tick_params(labelsize=12)\n",
    "    cbar.set_label('I4 brightness temperature (K)', size=12)\n",
    "\n",
    "    #Level 1 imagery plus detections\n",
    "    ax2.set_extent([EXTENT[0],EXTENT[2],EXTENT[1],EXTENT[3]])\n",
    "    plot = ax2.pcolormesh(lon, lat, i4_bt, vmin=250, vmax=360, cmap='plasma', transform=ccrs.PlateCarree())\n",
    "    cbar = plt.colorbar(plot, orientation='horizontal', shrink=0.6, pad=-2.2, extend='both', ax=ax6)\n",
    "    cbar.ax.tick_params(labelsize=12)\n",
    "    cbar.set_label('I4 brightness temperature (K)', size=12)\n",
    "\n",
    "    ax2.scatter(i_dets.longitude, i_dets.latitude, c=cmp2(i_dets['fire_mask'].astype(int)), s=0.5, transform=ccrs.Geodetic())\n",
    "    ax2.text(0.2, 0.9, 'Known fire pixels', c='black', transform = ax2.transAxes, fontsize=12)\n",
    "    ax2.text(0.2, 0.85, 'Candidate fire pixels', c='white', transform = ax2.transAxes, fontsize=12)\n",
    "    ax2.set_title(f'{SATELLITE} {date} {time}h UTC')\n",
    "\n",
    "    #Level 2 fire mask\n",
    "    ax3.set_extent([EXTENT[0],EXTENT[2],EXTENT[1],EXTENT[3]])\n",
    "    plot = ax3.pcolormesh(lon, lat, fire, vmin=0, vmax=10, cmap=cmp1, transform=ccrs.PlateCarree())\n",
    "\n",
    "    #Level 2 fire mask legend\n",
    "    cbar = plt.colorbar(plot, orientation='vertical', shrink=0.8, pad=-1, ax=ax4)\n",
    "\n",
    "    labels = ['0 not-processed', '1 bowtie', '2 glint', '3 water','4 clouds',\n",
    "          '5 clear land','6 unclassified fire pixel','7 low confidence fire pixel',\n",
    "          '8 nominal confidence fire pixel','9 high confidence fire pixel']\n",
    "    cbar.ax.set_yticks(np.arange(len(labels))+0.5)\n",
    "    cbar.ax.set_yticklabels(labels) \n",
    "    cbar.ax.tick_params(labelsize=12)\n",
    "    #cbar.set_label('Fire mask', size=13)\n",
    "    #ax3.set_title('Fire mask')\n",
    "\n",
    "    ax4.axis('off')\n",
    "    ax5.axis('off')\n",
    "    ax6.axis('off')\n",
    "    ax7.axis('off')\n",
    "    ax8.axis('off')\n",
    "    plt.savefig(f'/projects/shared-buckets/coffield/figures/creek_{timestamp[0]}-{timestamp[1]}_{SATELLITE}.png', dpi=150, bbox_inches='tight')\n",
    "\n",
    "    all_dets = pd.concat([all_dets, i_dets])\n",
    "    \n",
    "#save csv with filename as the timestamp range\n",
    "#all_dets.to_csv(f'/projects/shared-buckets/coffield/??PATH??{timestamp[0]}_{SATELLITE}.csv', index=False)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7214cb50-cd9d-42b4-9e7c-15832924c292",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3>Check each QA bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71a1abe-cfb8-43b9-ad32-e14e6ba468ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(6,len(files[products[0]])): #VNP03IMG or VJ103IMG\n",
    "    timestamp = files[products[0]][i].path.split('.')[-5:-3]\n",
    "    print(timestamp)\n",
    "    year = timestamp[0][1:5]\n",
    "    day = timestamp[0][5:8]\n",
    "    time = timestamp[1]\n",
    "    date = dt.datetime.strptime(year+day, '%Y%j').strftime('%b %d') \n",
    "    acq_datetime = dt.datetime.strptime(year+day+time[:2]+time[2:], '%Y%j%H%M').strftime('%Y-%m-%d %H:%M:00 +00:00') \n",
    "    daytime = int(time) > 1500 #depends on timezone\n",
    "\n",
    "    try:\n",
    "        #open VNP03IMG geolocation\n",
    "        geo = xr.open_dataset(files[products[0]][i], engine='h5netcdf', group='geolocation_data')\n",
    "        lon = geo['longitude'][:]\n",
    "        lat = geo['latitude'][:]\n",
    "        \n",
    "        scene = (lon > EXTENT[0]) & (lon < EXTENT[2]) & (lat > EXTENT[1]) & (lat < EXTENT[3])\n",
    "\n",
    "        #crop down the datasets for memory \n",
    "        indices = np.where(scene)\n",
    "        x0 = indices[0].min()\n",
    "        x1 = indices[0].max()\n",
    "        y0 = indices[1].min()\n",
    "        y1 = indices[1].max()\n",
    "\n",
    "        lon = lon[x0:x1, y0:y1]\n",
    "        lat = lat[x0:x1, y0:y1]\n",
    "        \n",
    "        #get VNP02IMG science data, i1-i5 bands\n",
    "        data = xr.open_dataset(files[products[1]][i], phony_dims='sort')\n",
    "        data = data.sel(phony_dim_1=slice(x0,x1), phony_dim_2=slice(y0,y1))\n",
    "        \n",
    "        qa = data.variables['algorithm QA'][:]\n",
    "        fire = data.variables['fire mask'][:]  \n",
    "\n",
    "    except:\n",
    "        print('error with file or does not exist',timestamp)\n",
    "        stop\n",
    "        continue\n",
    "    \n",
    "    #look at QA flags data next over entire scene\n",
    "    values, counts = np.unique(qa, return_counts=True)\n",
    "\n",
    "    table = pd.DataFrame(index = values, columns=range(22,-1,-1)) #[22,21,...0]\n",
    "    for i1 in table.index:\n",
    "        b = np.binary_repr(i1, width=23)\n",
    "        b = [int(s) for s in b]\n",
    "        table.loc[i1, :] = b\n",
    "    table['count'] = counts\n",
    "    \n",
    "    #eights += table[(table.loc[:,8] == 1)]['count'].sum()\n",
    "    #tens += table[(table.loc[:,10] == 1)]['count'].sum()\n",
    "    #noaa20_sums += table.iloc[:,:-1].multiply(table['count'], axis=\"index\").sum()\n",
    "    #print('---------', table[(table.loc[:,8] == 1)]['count'].sum(), table[(table.loc[:,10] == 1)]['count'].sum())\n",
    "    \n",
    "    '''\n",
    "    #create new dataset with bands for each QA bit yes/no\n",
    "    ds = xr.Dataset(\n",
    "        data_vars=dict(\n",
    "            qa=([\"x\", \"y\"], qa)\n",
    "        ),\n",
    "        coords=dict(\n",
    "            lon=([\"x\", \"y\"], lon),\n",
    "            lat=([\"x\", \"y\"], lat),\n",
    "        ),\n",
    "        attrs=dict(description=\"quality assurance bits\"),\n",
    "    )\n",
    "    ds = ds.where((ds.lon > extent[0]) & (ds.lon < extent[1]) & (ds.lat > extent[2]) & (ds.lat < extent[3]))\n",
    "    \n",
    "    for i in range(2):\n",
    "        ds = ds.assign(name = lambda ds: ds.qa * 0)\n",
    "        ds = ds.rename({'name':'bit'+str(i)})\n",
    "    '''\n",
    "    \n",
    "    bits = np.zeros((lon.shape[0], lon.shape[1], 23))\n",
    "    \n",
    "    for i in table.index[1:]: #skip the first row (zero)\n",
    "        locs = np.where(qa==i)\n",
    "        \n",
    "        b = np.binary_repr(i, width=23)[::-1]\n",
    "        bit_locs = [j for j in range(len(b)) if b[j]=='1']\n",
    "        \n",
    "        for bit in bit_locs:\n",
    "            bits[locs[0],locs[1],bit] = 1\n",
    "        \n",
    "        del locs, b, bit_locs\n",
    "    \n",
    "    \n",
    "    #figure: map of one QA bit\n",
    "    fig = plt.figure(figsize=(19,15))\n",
    "\n",
    "    for b in range(bits.shape[2]):\n",
    "        ax = plt.subplot(4,6,b+1, projection = ccrs.Miller())\n",
    "\n",
    "        #left panel map\n",
    "        ax.set_extent([EXTENT[0],EXTENT[2],EXTENT[1],EXTENT[3]])\n",
    "        ax.pcolormesh(lon, lat, bits[:,:,b], vmin=0, vmax=1, transform=ccrs.PlateCarree())\n",
    "        ax.set_title('Bit {}'.format(b))\n",
    "\n",
    "    plt.suptitle(f'{SATELLITE} {date} {year} {time}h', fontsize=18, weight='bold')\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig('/discover/nobackup/scoffie1/figures/bits/noaa20-{}-{}-{}.png'.format(day, year, time), dpi=150)\n",
    "    #plt.close()\n",
    "    stop\n",
    "    \n",
    "    \n",
    "    '''    \n",
    "    #build pandas table for exporting, following VIIRS L2 columns\n",
    "    i_dets = pd.DataFrame() #copy of master table just for this swath\n",
    "    i_dets['longitude'] = list(np.array(lon)[fires])\n",
    "    i_dets['latitude'] = list(np.array(lat)[fires])\n",
    "    i_dets['acq_date'] = dt.datetime.strptime(year+day, '%Y%j').strftime('%Y/%m/%d') \n",
    "    i_dets['acq_time'] = time\n",
    "    i_dets['acq_datetime'] = acq_datetime\n",
    "   \n",
    "    #crop down to defined extent\n",
    "    i_dets = i_dets[(i_dets.longitude > EXTENT[0]) & (i_dets.longitude < EXTENT[2]) & (i_dets.latitude > EXTENT[1]) & (i_dets.latitude < EXTENT[3])]\n",
    "    '''\n",
    "    #FIGURE ----------------\n",
    "    fig = plt.figure(figsize=(11,8))\n",
    "\n",
    "    ax = fig.add_subplot(121, projection=ccrs.Miller())\n",
    "    ax.set_extent([EXTENT[0],EXTENT[2],EXTENT[1],EXTENT[3]])\n",
    "    plot = ax.pcolormesh(lon, lat, fire, vmin=0, vmax=10, cmap='plasma', transform=ccrs.PlateCarree())\n",
    "    cbar = plt.colorbar(plot, orientation='horizontal', shrink=0.6, pad=0.01, extend='both', ax=ax)\n",
    "    cbar.ax.tick_params(labelsize=13)\n",
    "    cbar.set_label('I4 brightness temperature (K)', size=13)\n",
    "    ax.set_title(f'{SATELLITE} {date} {time}h UTC') \n",
    "    stop         \n",
    "    ax2 = fig.add_subplot(122, projection=ccrs.Miller())\n",
    "    ax2.set_extent([EXTENT[0],EXTENT[2],EXTENT[1],EXTENT[3]])\n",
    "    plot = ax2.pcolormesh(lon, lat, i4_bt, vmin=250, vmax=360, cmap='plasma', transform=ccrs.PlateCarree())\n",
    "    cbar = plt.colorbar(plot, orientation='horizontal', shrink=0.6, pad=0.01, extend='both', ax=ax2)\n",
    "    cbar.ax.tick_params(labelsize=13)\n",
    "    cbar.set_label('I4 brightness temperature (K)', size=13)\n",
    "    ax2.scatter(i_dets.longitude, i_dets.latitude, c='1', s=1, transform=ccrs.Geodetic())\n",
    "    ax2.text(0.35, 0.9, 'Potential fire pixels', c='white', transform = ax2.transAxes)\n",
    "    \n",
    "    #plt.savefig(f'/projects/shared-buckets/coffield/??PATH??{timestamp[0]}-{timestamp[1]}_{SATELLITE}.png', dpi=150)\n",
    "\n",
    "    all_dets = pd.concat([all_dets, i_dets])\n",
    "    \n",
    "#save csv with filename as the timestamp range\n",
    "#all_dets.to_csv(f'/projects/shared-buckets/coffield/??PATH??{timestamp[0]}_{SATELLITE}.csv', index=False)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d899410-ddb6-45b2-9894-58e568ffe3b2",
   "metadata": {},
   "source": [
    "<h3>Old code / debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95841873-0a83-4ede-ad67-62b119070aee",
   "metadata": {},
   "source": [
    "Issue: cannot earthaccess.open on both VNP03IMG and VNP14IMG consecutively. Requires restarting the kernel and doing one or the other. Current workaround: download the VNP14IMGs, then restart and stream the VNP03IMG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9637522e-787b-4c0f-9060-8bc8caab5386",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#run once then restart kernel\n",
    "results = earthaccess.search_data(\n",
    "    short_name='VNP14IMG',\n",
    "    bounding_box=(EXTENT[0],EXTENT[1],EXTENT[2],EXTENT[3]),\n",
    "    temporal=(START, END),\n",
    "    count=10\n",
    ")\n",
    "#files = earthaccess.open(results)\n",
    "files = earthaccess.download(results, '/projects/shared-buckets/coffield/viirs/VNP14IMG')\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3042438-f962-4636-9356-b68e155fbdb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "files = {}\n",
    "\n",
    "results = earthaccess.search_data(\n",
    "    short_name='VNP03IMG',\n",
    "    bounding_box=(EXTENT[0],EXTENT[1],EXTENT[2],EXTENT[3]),\n",
    "    temporal=(START, END),\n",
    "    count=10\n",
    ")\n",
    "\n",
    "files[product] = earthaccess.open(results)\n",
    "\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91076e05-a5f1-469c-9d25-c61dadbdc19b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "files = {}\n",
    "for product in products:\n",
    "    #query for granules - by bounding box or point\n",
    "    results = earthaccess.search_data(\n",
    "        short_name=product,\n",
    "        bounding_box=(EXTENT[0],EXTENT[1],EXTENT[2],EXTENT[3]),\n",
    "        temporal=(START, END),\n",
    "        count=10\n",
    "    )\n",
    "\n",
    "    files[product] = earthaccess.open(results)\n",
    "    \n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f97123-5024-4829-b123-eb13c06fed3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "boto3.client('s3').meta.region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed9a591-41a9-457d-9ceb-190b3b181010",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "files['VNP14IMG'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e643cf2-73f6-4a27-8709-c88a4ffd40e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "foo = xr.open_dataset(files[0]), phony_dims='sort')\n",
    "foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f529eb63-7161-4fc2-b500-6ab954c78032",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(foo['fire mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79acd77b-77ed-41d3-994f-83c41145386b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AGAIN FOR SNPP (new) \n",
    "\n",
    "#count QA flags for each swath\n",
    "\n",
    "root = '/css/viirs/data/'\n",
    "\n",
    "with open('/home/scoffie1/links/creek_VJ103IMG_sep2020_day.txt', 'r') as links: # VJ103IMG_082020_amazon.txt\n",
    "    files = links.readlines()\n",
    "\n",
    "#files = os.listdir(root + 'Level1/VJ103IMG.trimmed/2020/245') #ANYWHERE IN THE WORLD\n",
    "files = os.listdir('/discover/nobackup/scoffie1/VJ114IMG')\n",
    "files = [f for f in files if f[-2:]=='nc']\n",
    "\n",
    "files = ['VNP03IMG.A2020251.2042.002.2021125052211.nc']\n",
    "files = ['VNP03IMG.A2020251.0924']\n",
    "files = sorted(files)\n",
    "print(files)\n",
    "\n",
    "values_noaa20_mask = np.array([])\n",
    "eights = 0\n",
    "tens = 0\n",
    "noaa20_sums = 0\n",
    "\n",
    "for file in files:\n",
    "    day = file.split('.')[1][-3:]\n",
    "    year = file.split('.')[1][1:5]\n",
    "    date = dt.datetime.strptime(year+day, '%Y%j').strftime('%b %d') \n",
    "    time = file.split('.')[2] #time kept as a string - may affect plot titles\n",
    "    print(day, time)\n",
    "\n",
    "    try:\n",
    "        #get VJ103 geolocation\n",
    "        matches = os.listdir(root + 'Level1/VNP03IMG.trimmed/2020/' + day)\n",
    "        matches = [match for match in matches if match[18:22] == time]\n",
    "        geo = netCDF4.Dataset(root + 'Level1/VNP03IMG.trimmed/2020/' + day + '/' + matches[0])\n",
    "        lon = geo.groups['geolocation_data']['longitude'][:]\n",
    "        lat = geo.groups['geolocation_data']['latitude'][:]\n",
    "\n",
    "        #get VJ114 fire mask + qa\n",
    "        matches = os.listdir(root + 'Level2/VNP14IMG/2020/' + day)\n",
    "        matches = [match for match in matches if match[18:22] == time]\n",
    "        data = netCDF4.Dataset(root + 'Level2/VNP14IMG/2020/' + day + '/' + matches[0])\n",
    "        #data = netCDF4.Dataset('/home/scoffie1/VNP14IMG/VNP14IMG.A2020251.2042.002.2023008022048.nc') #COLLECTION2\n",
    "        data = netCDF4.Dataset('/home/scoffie1/VNP14IMG/VNP14IMG.A2020251.0924.002.2023008022055.nc') #COLLECTION2\n",
    "        \n",
    "        qa = data.variables['algorithm QA']\n",
    "        fire = data.variables['fire mask']\n",
    "    \n",
    "    except:\n",
    "        print('error with file',file)\n",
    "        continue\n",
    "\n",
    "    scene = (lon > extent[0]) & (lon < extent[1]) & (lat > extent[2]) & (lat < extent[3])\n",
    "\n",
    "    #fire mask for entire scene flags data next over entire scene\n",
    "    scene_mask = np.array(fire)[scene] \n",
    "    \n",
    "    values_noaa20_mask = np.concatenate([values_noaa20_mask, scene_mask])\n",
    "    \n",
    "    #look at QA flags data next over entire scene\n",
    "    scene_qa = np.array(qa)[scene] #[uncs][fires] #can play with subsetting\n",
    "    values, counts = np.unique(scene_qa, return_counts=True)\n",
    "\n",
    "    table = pd.DataFrame(index = values, columns=range(22,-1,-1)) #[22,21,...0]\n",
    "    for i1 in table.index:\n",
    "        b = np.binary_repr(i1, width=23)\n",
    "        b = [int(s) for s in b]\n",
    "        table.loc[i1, :] = b\n",
    "    table['count'] = counts\n",
    "    \n",
    "    eights += table[(table.loc[:,8] == 1)]['count'].sum()\n",
    "    tens += table[(table.loc[:,10] == 1)]['count'].sum()\n",
    "    noaa20_sums += table.iloc[:,:-1].multiply(table['count'], axis=\"index\").sum()\n",
    "    print('---------', table[(table.loc[:,8] == 1)]['count'].sum(), table[(table.loc[:,10] == 1)]['count'].sum())\n",
    "    \n",
    "    '''\n",
    "    #create new dataset with bands for each QA bit yes/no\n",
    "    ds = xr.Dataset(\n",
    "        data_vars=dict(\n",
    "            qa=([\"x\", \"y\"], qa)\n",
    "        ),\n",
    "        coords=dict(\n",
    "            lon=([\"x\", \"y\"], lon),\n",
    "            lat=([\"x\", \"y\"], lat),\n",
    "        ),\n",
    "        attrs=dict(description=\"quality assurance bits\"),\n",
    "    )\n",
    "    ds = ds.where((ds.lon > extent[0]) & (ds.lon < extent[1]) & (ds.lat > extent[2]) & (ds.lat < extent[3]))\n",
    "    \n",
    "        \n",
    "    for i in range(2):\n",
    "        ds = ds.assign(name = lambda ds: ds.qa * 0)\n",
    "        ds = ds.rename({'name':'bit'+str(i)})\n",
    "    '''\n",
    "    \n",
    "    bits = np.zeros((lon.shape[0], lon.shape[1], 23))\n",
    "    qa = np.ma.masked_where(~scene, qa)\n",
    "    \n",
    "    for i in table.index[1:]: #skip the first row (zero)\n",
    "        locs = np.where(qa==i)\n",
    "        \n",
    "        b = np.binary_repr(i, width=23)[::-1]\n",
    "        bit_locs = [j for j in range(len(b)) if b[j]=='1']\n",
    "        \n",
    "        for bit in bit_locs:\n",
    "            bits[locs[0],locs[1],bit] = 1\n",
    "        \n",
    "        del locs, b, bit_locs\n",
    "    \n",
    "    \n",
    "    #four corners for cropping\n",
    "    corners = np.where(~qa.mask)\n",
    "    if len(corners[0]) > 0: #if there is any data in the scene\n",
    "        x0 = corners[0].min()\n",
    "        x1 = corners[0].max()\n",
    "        y0 = corners[1].min()\n",
    "        y1 = corners[1].max()\n",
    "\n",
    "\n",
    "        #figure: map of one QA bit\n",
    "        fig = plt.figure(figsize=(19,15))\n",
    "\n",
    "        for b in range(bits.shape[2]):\n",
    "            ax = plt.subplot(4,6,b+1, projection = ccrs.Miller())\n",
    "\n",
    "            #left panel map\n",
    "            ax.set_extent(extent)\n",
    "            ax.pcolormesh(lon[x0:x1, y0:y1], lat[x0:x1, y0:y1], bits[x0:x1, y0:y1][:,:,b], vmin=0, vmax=1, transform=ccrs.PlateCarree())\n",
    "            ax.set_title('Bit {}'.format(b))\n",
    "\n",
    "        plt.suptitle('SNPP {} {} {}'.format(date, year, time), fontsize=18, weight='bold')\n",
    "        plt.tight_layout()\n",
    "        #plt.savefig('/discover/nobackup/scoffie1/figures/bits/noaa20-{}-{}-{}.png'.format(day, year, time), dpi=150)\n",
    "        #plt.close()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python candidatesenv",
   "language": "python",
   "name": "candidates-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
