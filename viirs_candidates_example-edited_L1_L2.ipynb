{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe9592f3-0e1d-40ac-af59-7eb7d05c463d",
   "metadata": {},
   "source": [
    "Search for granules on the cloud for a box of interest, run custom candidate fire pixel extraction, map I4 + custom candidates. Searching for VIIRS L2 fire data (swaths and text files) in the cloud and checking which versions are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8488ca2-6176-4227-ab0f-d1d21e07d3da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# %time is not the same as %%time because the former only see's how long the current \n",
    "#line takes to execute, whereas the latter checks the how the current line and \n",
    "#following lines take to execute\n",
    "#[:] is the array slice syntax for every element in the array\n",
    "\n",
    "\n",
    "\n",
    "#conda activate /projects/myenvs/candidates-env\n",
    "import xarray as xr\n",
    "import earthaccess\n",
    "from earthaccess import Auth, Store, DataCollections, DataGranules\n",
    "import datetime as dt\n",
    "from datetime import timedelta\n",
    "import time\n",
    "import os\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import folium\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import pandas as pd\n",
    "import rioxarray\n",
    "from scipy.spatial.distance import cdist\n",
    "import matplotlib as mpl\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "#read in pyroCB catalog\n",
    "file = f'/projects/shared-buckets/qulizad/NRL_pyroCb_inventory_2023_v1.csv'\n",
    "df = pd.read_csv(file, header=0, usecols=[\"datetime\", \"fire_name\", \"region\", \"lat\", \"lon\"])\n",
    "rslt_df = df.loc[(df['region'] == 'Canada')]  #.reset_index(drop=True) #subsetting to Canada\n",
    "#rslt_df.loc[5] ## only prints up to not including 10th record\n",
    "output_dir = '/projects/shared-buckets/qulizad/scripts/outputs/canada/'\n",
    "\n",
    "for i in rslt_df.index[96:98]: \n",
    "    fire_name = rslt_df.loc[i, 'fire_name']\n",
    "    lat = rslt_df.loc[i, 'lat']\n",
    "    lon = rslt_df.loc[i, 'lon']\n",
    "    dat = rslt_df.loc[i, 'datetime']\n",
    "    date_object = dt.datetime.strptime(dat, \"%m/%d/%y %H:%M\")    \n",
    "    print(i, fire_name, date_object)\n",
    "    #date_object is pyrocb event time\n",
    "    \n",
    "    start_date = date_object + dt.timedelta(-2)\n",
    "    end_date = date_object + dt.timedelta(+2)\n",
    "\n",
    "    start_date = start_date.strftime(\"%Y-%m-%d\")\n",
    "    end_date = end_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    EXTENT = [lon - 0.5, lat - 0.5, lon + 0.5, lat + 0.5]\n",
    "    START = start_date\n",
    "    END = end_date\n",
    "\n",
    "\n",
    "    satellites = ['SNPP','NOAA20']\n",
    "    for s in satellites:\n",
    "        #s3_links, files = fetch_data(s)\n",
    "        if s=='SNPP': products = ['VNP03IMG','VNP02IMG','VNP14IMG']\n",
    "        elif s=='NOAA20': products = ['VJ103IMG','VJ102IMG','VJ114IMG']\n",
    "        print(products)\n",
    "\n",
    "        #run_fire_algorithm() #using level 1 data\n",
    "\n",
    "        #run_custom_fire_algorithm(s3_links, files) #using level 1 data\n",
    "        #run_viirs_l2_fire_algoithm(s3_links, files) #using level 2 data\n",
    "        \n",
    "        #first get the L1 geolocation and science data via direct S3 access\n",
    "        #may require restarting the kernel if permission errors\n",
    "\n",
    "        files = {}\n",
    "\n",
    "        #geolocation 03IMG\n",
    "        results = earthaccess.search_data(\n",
    "            short_name=products[0],\n",
    "            bounding_box=(EXTENT[0],EXTENT[1],EXTENT[2],EXTENT[3]),\n",
    "            temporal=(START, END),\n",
    "            count=100\n",
    "        )\n",
    "        files[products[0]] = earthaccess.open(results)\n",
    "\n",
    "        #science data 02IMG\n",
    "        results = earthaccess.search_data(\n",
    "            short_name=products[1],\n",
    "            bounding_box=(EXTENT[0],EXTENT[1],EXTENT[2],EXTENT[3]),\n",
    "            temporal=(START, END),\n",
    "            count=100\n",
    "        )\n",
    "        files[products[1]] = earthaccess.open(results)\n",
    "\n",
    "        files\n",
    "        \n",
    "        #initiate cloud session - need to reauthenticate every hour :(\n",
    "        auth = Auth() \n",
    "        #auth.login(strategy=\"interactive\", persist=True) #RUN THIS THE FIRST TIME\n",
    "        auth.login(strategy=\"netrc\") #read credentials from previously saved ~/.netrc file\n",
    "\n",
    "        store = Store(auth)\n",
    "        fs = store.get_s3fs_session('LAADS') #daac or provider name\n",
    "        \n",
    "        product = products[2]\n",
    "\n",
    "        Query = DataGranules().short_name(product).bounding_box(EXTENT[0],EXTENT[1],EXTENT[2],EXTENT[3]).temporal(START,END)\n",
    "\n",
    "        print(Query.hits(), 'hits')\n",
    "        cloud_granules = Query.get(800) #first 800 results\n",
    "        print('cloud hosted', cloud_granules[0].cloud_hosted)\n",
    "\n",
    "        s3_links = {}\n",
    "        s3_links[product] = []\n",
    "        for granule in cloud_granules:\n",
    "            s3_links[product].extend(granule.data_links(access=\"in-region\"))\n",
    "        s3_links[product] = sorted(s3_links[product]) \n",
    "        files[product] = store.open(s3_links[product], provider=\"LAADS\")\n",
    "\n",
    "        print(product)\n",
    "        pprint(files)\n",
    "        \n",
    "        mask_colors = [mpl.colormaps['tab10'](c) for c in [4,6,5,0,9,2,7,8,1,3]] #fire mask colors\n",
    "        dets_colors = ['white']*7 + ['black']*3                                  #black and white version\n",
    "\n",
    "        cmp1 = ListedColormap(mask_colors)\n",
    "        cmp2 = ListedColormap(dets_colors)\n",
    "        \n",
    "        all_dets = pd.DataFrame()\n",
    "\n",
    "        for i in range(len(files[products[0]])): #VNP03IMG or VJ103IMG\n",
    "            timestamp = files[products[0]][i].path.split('.')[-5:-3]\n",
    "            print(timestamp)\n",
    "            year = timestamp[0][1:5]\n",
    "            day = timestamp[0][5:8]\n",
    "            time = timestamp[1]\n",
    "            date = dt.datetime.strptime(year+day, '%Y%j').strftime('%b %d') \n",
    "            acq_datetime_obj = dt.datetime.strptime(year+day+time[:2]+time[2:], '%Y%j%H%M')\n",
    "            acq_datetime = acq_datetime_obj.strftime('%Y-%m-%d %H:%M:00 +00:00') \n",
    "            daytime = int(time) > 1500 #depends on timezone\n",
    "            \n",
    "            #calculate the time difference \n",
    "            diff = date_object - acq_datetime_obj\n",
    "            diff / dt.timedelta(hours=1)\n",
    "            print(diff)\n",
    "            \n",
    "            try:\n",
    "                #open 03IMG geolocation\n",
    "                geo = xr.open_dataset(files[products[0]][i], engine='h5netcdf', group='geolocation_data')\n",
    "                lon = geo['longitude'][:]\n",
    "                lat = geo['latitude'][:]\n",
    "                _, j = np.indices(geo.longitude.shape) #line and sample\n",
    "\n",
    "                scene = (lon > EXTENT[0]) & (lon < EXTENT[2]) & (lat > EXTENT[1]) & (lat < EXTENT[3])\n",
    "\n",
    "                #crop down the datasets for memory \n",
    "                indices = np.where(scene)\n",
    "                x0 = indices[0].min()\n",
    "                x1 = indices[0].max()\n",
    "                y0 = indices[1].min()\n",
    "                y1 = indices[1].max()\n",
    "\n",
    "                lon = lon[x0:x1, y0:y1]\n",
    "                lat = lat[x0:x1, y0:y1]\n",
    "                j = j[x0:x1, y0:y1]\n",
    "\n",
    "                #open 02IMG science data, i4 band\n",
    "                data = xr.open_dataset(files[products[1]][i], engine='h5netcdf', group='observation_data')\n",
    "                data = data.sel(number_of_lines=slice(x0,x1), number_of_pixels=slice(y0,y1))\n",
    "\n",
    "                i4 = data['I04'] #xarray already encodes the scale factor and offset\n",
    "                scale = data.I04.encoding['scale_factor']\n",
    "                offset = data.I04.encoding['add_offset']\n",
    "                i4 = (i4[:,:] - offset) / scale #return to raw values to use lookup table to temperature\n",
    "                i4 = i4.astype(int)\n",
    "                i4_bt = data['I04_brightness_temperature_lut'][:]\n",
    "                i4_bt = i4_bt[i4]\n",
    "\n",
    "                #get VNP14IMG\n",
    "                match = [f for f in files[products[2]] if timestamp[0] and timestamp[1] in f.path][0]\n",
    "                data = xr.open_dataset(match, phony_dims = 'sort')\n",
    "                data = data.sel(phony_dim_1=slice(x0,x1), phony_dim_2=slice(y0,y1))\n",
    "                daynight = data.DayNightFlag #string Day or Night\n",
    "\n",
    "                qa = data.variables['algorithm QA'][:]\n",
    "                fire = data.variables['fire mask'][:]  \n",
    "                fires = (fire>6).values\n",
    "\n",
    "            except:\n",
    "                print('error with file',timestamp)\n",
    "                #stop\n",
    "                continue\n",
    "\n",
    "            #look at QA flags data next over entire scene\n",
    "            values, counts = np.unique(qa, return_counts=True)\n",
    "\n",
    "            table = pd.DataFrame(index = values, columns=range(22,-1,-1)) #[22,21,...0]\n",
    "            for i1 in table.index:\n",
    "                b = np.binary_repr(i1, width=23)\n",
    "                b = [int(s) for s in b]\n",
    "                table.loc[i1, :] = b\n",
    "\n",
    "            #report back all the pixels that have an 8 or 10 ~ background or candidate fires\n",
    "            keep = table[(table.loc[:,8]==1) | (table.loc[:,10]==1)].index\n",
    "            keep = (np.isin(qa[:], keep) | (fires))  #\"fires\" because some low conf are Test 16 pixel saturation\n",
    "\n",
    "\n",
    "            #build pandas table for exporting, following VIIRS L2 columns\n",
    "            i_dets = pd.DataFrame()\n",
    "            i_dets['longitude'] = list(lon.values[keep])\n",
    "            i_dets['latitude'] = list(lat.values[keep])\n",
    "            i_dets['fire_mask'] = list(fire.values[keep])\n",
    "            i_dets['daynight'] = daynight[0]\n",
    "            i_dets['confidence'] = i_dets.fire_mask\n",
    "            i_dets.confidence = i_dets.confidence.replace({0:'x', 1:'x', 2:'x', 3:'x', 4:'x', 5:'x', 6:'x', 7:'l', 8:'n', 9:'h'})\n",
    "            i_dets['acq_date'] = date\n",
    "            i_dets['acq_time'] = time\n",
    "            i_dets['acq_datetime'] = acq_datetime\n",
    "            i_dets['j'] = list(j[keep]) #sample number for pixel size lookup\n",
    "\n",
    "            #crop down to defined extent\n",
    "            i_dets = i_dets[(i_dets.longitude > EXTENT[0]) & (i_dets.longitude < EXTENT[2]) & (i_dets.latitude > EXTENT[1]) & (i_dets.latitude < EXTENT[3])]\n",
    "\n",
    "            #FIGURE ----------------\n",
    "\n",
    "            fig, ((ax,ax2,ax3,ax4),(ax5,ax6,ax7,ax8)) = plt.subplots(2,4, gridspec_kw={'width_ratios':[3,3,3,1], 'height_ratios':[6,1]}, constrained_layout=True, subplot_kw={'projection':ccrs.Miller()}, figsize=(12,8))\n",
    "\n",
    "            #Level 1 imagery\n",
    "            ax.set_extent([EXTENT[0],EXTENT[2],EXTENT[1],EXTENT[3]])\n",
    "            plot = ax.pcolormesh(lon, lat, i4_bt, vmin=250, vmax=360, cmap='plasma', transform=ccrs.PlateCarree())\n",
    "            cbar = plt.colorbar(plot, orientation='horizontal', shrink=0.6, pad=-2.2, extend='both', ax=ax5)\n",
    "            cbar.ax.tick_params(labelsize=12)\n",
    "            cbar.set_label('I4 brightness temperature (K)', size=12)\n",
    "\n",
    "            #Level 1 imagery plus detections\n",
    "            ax2.set_extent([EXTENT[0],EXTENT[2],EXTENT[1],EXTENT[3]])\n",
    "            plot = ax2.pcolormesh(lon, lat, i4_bt, vmin=250, vmax=360, cmap='plasma', transform=ccrs.PlateCarree())\n",
    "            cbar = plt.colorbar(plot, orientation='horizontal', shrink=0.6, pad=-2.2, extend='both', ax=ax6)\n",
    "            cbar.ax.tick_params(labelsize=12)\n",
    "            cbar.set_label('I4 brightness temperature (K)', size=12)\n",
    "\n",
    "            ax2.scatter(i_dets.longitude, i_dets.latitude, c=cmp2(i_dets['fire_mask'].astype(int)), s=0.5, transform=ccrs.Geodetic())\n",
    "            ax2.text(0.2, 0.9, 'Known fire pixels', c='black', transform = ax2.transAxes, fontsize=12)\n",
    "            ax2.text(0.2, 0.85, 'Candidate fire pixels', c='white', transform = ax2.transAxes, fontsize=12)\n",
    "             \n",
    "            # if statement\n",
    "            #if diff \n",
    "            ax2.set_title(f'{s} {date} {time}h UTC') \n",
    "           \n",
    "            #print out pyrocb time\n",
    "\n",
    "            #Level 2 fire mask\n",
    "            ax3.set_extent([EXTENT[0],EXTENT[2],EXTENT[1],EXTENT[3]])\n",
    "            plot = ax3.pcolormesh(lon, lat, fire, vmin=0, vmax=10, cmap=cmp1, transform=ccrs.PlateCarree())\n",
    "\n",
    "            #Level 2 fire mask legend\n",
    "            cbar = plt.colorbar(plot, orientation='vertical', shrink=0.8, pad=-1, ax=ax4)\n",
    "\n",
    "            labels = ['0 not-processed', '1 bowtie', '2 glint', '3 water','4 clouds',\n",
    "                  '5 clear land','6 unclassified fire pixel','7 low confidence fire pixel',\n",
    "                  '8 nominal confidence fire pixel','9 high confidence fire pixel']\n",
    "            cbar.ax.set_yticks(np.arange(len(labels))+0.5)\n",
    "            cbar.ax.set_yticklabels(labels) \n",
    "            cbar.ax.tick_params(labelsize=12)\n",
    "            #cbar.set_label('Fire mask', size=13)\n",
    "            #ax3.set_title('Fire mask')\n",
    "\n",
    "            ax4.axis('off')\n",
    "            ax5.axis('off')\n",
    "            ax6.axis('off')\n",
    "            ax7.axis('off')\n",
    "            ax8.axis('off')\n",
    "            #if statement, else\n",
    "            plt.savefig(f'/projects/my-public-bucket/outputs/canada/{fire_name}/{timestamp[0]}-{timestamp[1]}_{s}.png', dpi=150, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            all_dets = pd.concat([all_dets, i_dets])\n",
    "\n",
    "        #save csv with filename as the timestamp range\n",
    "        all_dets.to_csv(f'/projects/my-public-bucket/outputs/canada/{fire_name}/{timestamp[0]}_{s}.csv', index=False)\n",
    "\n",
    "        print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa1e724-50a7-40db-8d44-c8e069ca4593",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aec0b0ee-abfb-4733-bc7f-cddd500f210f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2023, 7, 15, 2, 40)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "167744a5-d91d-435b-8d8e-8f57d2eac165",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2023, 7, 13, 9, 36)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acq_datetime_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63527aeb-2cb6-41a2-99c4-ad1f6610dfab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diff = date_object - acq_datetime_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "631b8bbd-f2a6-4423-ad9e-909c609055b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 day, 17:04:00\n"
     ]
    }
   ],
   "source": [
    "print(diff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60b9a84e-a54d-429e-a560-5e9c105f8c27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.06666666666667"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff/dt.timedelta(hours = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7d6f08f-ffec-4023-8443-0c2300330936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2023, 7, 15, 2, 40)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5880ca75-3145-4a1c-95b6-5921be216a25",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023-07-13 09:36:00 +00:00'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acq_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88294c6d-0275-426a-bd17-2d3555180e2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#turn acq_datetime into datetime object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ea8f2b9-44de-4cec-81da-a1d22f79281a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2023, 7, 13, 9, 36)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.datetime.strptime(year+day+time[:2]+time[2:], '%Y%j%H%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae2e17d-841e-4896-9099-f4d95cc8ec0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python candidatesenv",
   "language": "python",
   "name": "candidates-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
